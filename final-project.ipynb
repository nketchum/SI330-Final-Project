{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI 330 Final Project\n",
    "### Nicholas Ketchum, SI 330, Winter 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project create a visualization and correlation between unemployment insurance claims recorded by the Federal Reserve and covid cases in the United States. It uses public APIs and datasets to gather information, clean it, and store in a database. It then makes calculations and plots a visualization using dataframes. The motivation is to see how reported cases and employment were affected what the correlation is between new cases and initial unemployment claims over a one-year period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Establish a database connection**\n",
    "\n",
    "Using the sql extension and th sqlalchemy library, we will connect to the default database configuration provided by Jupyter through MichiganMads.org. This database will store data pulled from APIs and other sources for storage and queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Establish a database connection.\n",
    "%load_ext sql\n",
    "%sql postgres://jovyan:si330studentuser@localhost:5432/si330\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('postgres://jovyan:si330studentuser@localhost:5432/si330')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Import libraries and set data source variables**\n",
    "\n",
    "First, we go ahead and import all the other libraries we'll need in one spot. This makes it easier to keep track of what we've imported. For some reason, pandas requires an import of register_matplotlib_converters to properly plot some of my data.\n",
    "\n",
    "The next thing this cell does is execute register_matplotlib_converters() to load the pandas plotting extension, and then define my own specific Fed API key, for which I had to register, and the Fed API headers, which I like keeping one spot for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import requests\n",
    "\n",
    "# For some reason the \"register_matplotlib_converters\" class\n",
    "# is required for plotting on this platform.\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# Storing Fed api key and headers in one spot for more flexibility.\n",
    "FED_API_KEY = \"a964732354e30d669470642ff6b45f4c\"\n",
    "\n",
    "fed_api_settings = {\n",
    "    'series_id': 'ICSA',\n",
    "    'file_type': 'json',\n",
    "    'sort_order': 'desc',\n",
    "    'observation_start': \"2020-01-07\", # Trying to match the static end/start dates\n",
    "    'observation_end': \"2021-03-07\",   # provided by the Covid tracker.\n",
    "    'limit': '1300'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Retrieve Fed data from a public API using JSON**\n",
    "\n",
    "This function takes the predefined headers and API key and makes a request to gather one year's worth of data roughly aligning with the first year of the COVID-19 outbreak. It requests the JSON data, then rerads it into a dataframe, and then refactored into a new data frame that has a converted string date with an extra day added to each to align these dates with dates in the COVID-19 data set, which allows for joins.\n",
    "\n",
    "The additional day is immaterial because these are weekly measurements. Because we're looking at overall trends in rough form, we're not concerned if data is off by one day; we're looking at chart shapes more generally.\n",
    "\n",
    "Finally, the dataframe's index is set using the date column, and columns are renamed for clarity and convience before returning the dataframe to the original function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weekly numbers from a public API.\n",
    "def getFedData(settings):\n",
    "    headers = \"?series_id=\" + settings['series_id'] + \"&api_key=\" + FED_API_KEY + \"&file_type=\" + settings['file_type'] + \"&sort_order=\" + settings['sort_order'] + \"&observation_start=\" + settings['observation_start'] + \"&observation_end=\" + settings['observation_end'] + \"&limit=\" + str(settings['limit'])\n",
    "    url = \"https://api.stlouisfed.org/fred/series/observations\" + headers\n",
    "    df = pd.read_json(url)\n",
    "    ndf = pd.DataFrame()\n",
    "    for group, row in df.iterrows():\n",
    "        # Covid data is one day behind Fed data.\n",
    "        # To make our lives easier, let's add one day to Fed data so we can match records.\n",
    "        # A one-day delta is immaterial for our overall measurement and analysis.\n",
    "        ndf.loc[group, 'date'] = pd.to_datetime(df.iloc[group]['observations']['date']) + pd.Timedelta(days=1)\n",
    "        ndf.loc[group, 'total_new_claims'] = int(df.iloc[group]['observations']['value'])\n",
    "    ndf.set_index('date', inplace=True)\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Store Fed data into the database**\n",
    "\n",
    "This function creates a table to store Fed data. It drops any pre-existing tables, creates a new table with two columns: date (timestamp) and claims (integer). Then, the data is loaded from a dataframe by using the .to_sql() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store fed data in a db tabe.\n",
    "def storeFedData(df, engine):\n",
    "    %sql DROP TABLE IF EXISTS fed_data;\n",
    "    %sql CREATE TABLE fed_data(date timestamp, claims integer, PRIMARY KEY(date))\n",
    "    df.to_sql('fed_data', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Pull Fed data from the database**\n",
    "\n",
    "This function simply selects all records from the fed_data table, ordered by date, and returned as a sql result set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select fed data from db table.\n",
    "def selectFedData(engine):\n",
    "    results = %sql SELECT * FROM fed_data ORDER BY date ASC;\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Retrieve COVID-19 data from a public CSV file**\n",
    "\n",
    "This function requests a public CSV file listed at covidtracking.com. It uses the pandas read_csv method to convert the CSV data into a dataframe. Then, a new dataframe is created which stores a reformatted date and converts it into a pandas datetime.\n",
    "\n",
    "Nans are replaced with zeros to keep the dataframe shape the same as the Fed dataframe (keeping an identical row count), its positive_cases column datatype is converted to an integer using the apply() function to cast data as an int(), and then set as the dataframe index.\n",
    "\n",
    "Finally, the dataframe is resampled to a weekly interval, summing up the new cases from each day that week. Then the final, cleaned dataframe is returned to the original calling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cases from a public csv.\n",
    "def getCovidData():\n",
    "    url = 'https://api.covidtracking.com/v1/us/daily.csv'\n",
    "    # Entire dataframe with everything.\n",
    "    df = pd.read_csv(url)\n",
    "    # Empty dataframe will store what we need.\n",
    "    ndf = pd.DataFrame()\n",
    "    for group, row in df.iterrows():\n",
    "        # Format the data similar to Fed data.\n",
    "        date = row['date']\n",
    "        date = str(date)\n",
    "        year = date[0:4]\n",
    "        day = date[4:6]\n",
    "        month = date[6:8]\n",
    "        date = year + '-' + day + '-' + month\n",
    "        # Make date into a datetime type.\n",
    "        ndf.loc[group, 'date'] = pd.to_datetime(date)\n",
    "        positive_cases = row['positiveIncrease']\n",
    "        ndf.loc[group, 'positive_cases'] = positive_cases\n",
    "    # Get rid of empty yrecords.\n",
    "    ndf = ndf.replace(np.nan, 0)\n",
    "    # Convert positive case column type into an int.\n",
    "    ndf['positive_cases'] = ndf['positive_cases'].apply(int)\n",
    "    # Index via datetime.\n",
    "    ndf.set_index('date', inplace=True)\n",
    "    # Resample as a weekly sum of new cases.\n",
    "    ndf = ndf.resample('W').sum()\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Store COVID-19 data into the database**\n",
    "\n",
    "This function creates a table to store COVID-19 data. It drops any pre-existing tables, creates a new table with two columns: date (timestamp) and positive_cases (integer). Then, the data is loaded from a dataframe by using the .to_sql() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store fed data in a db tabe.\n",
    "def storeCovidData(df, engine):\n",
    "    %sql DROP TABLE IF EXISTS covid_data;\n",
    "    %sql CREATE TABLE covid_data(date timestamp, positive_cases integer, PRIMARY KEY(date))\n",
    "    df.to_sql('covid_data', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Pull COVID-19 data from the database**\n",
    "\n",
    "This function simply selects all records from the covid_data table, ordered by date, and returned as a sql result set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select fed data from db table.\n",
    "def selectCovidData(engine):\n",
    "    results = %sql SELECT * FROM covid_data ORDER BY date ASC;\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Select everthing stored in the database**\n",
    "\n",
    "This function joins the fed_data and covid_data table on the data field. This results in each record containing a date, number of new unemployment claims in a particular week, the number of new COVID-19 cases identified in that same week, and returns the data as a sql result set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select final records.\n",
    "def selectAllData(engine):\n",
    "    # Covid data is daily but Fed data is weekly. The join takes care of that.\n",
    "    results = %sql SELECT fed_data.date AS claim_date, fed_data.total_new_claims, covid_data.date AS covid_date, covid_data.positive_cases AS new_positive_cases FROM fed_data INNER JOIN covid_data ON fed_data.date = covid_data.date;\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Create a two dataframes for each datasest from the returned database queries**\n",
    "\n",
    "This function takes the sql result set returned from the above function, converts it into a \"master\" dataframe, renames the columns from integer indexes to readable lables, and sets the index using the date. Then, two new dataframes are created using the master dataframe: one for unemployment (Fed) and one for COVID-19. Both dataframes are returned to the original calling function as a tuple.\n",
    "\n",
    "\n",
    "Although created a \"master dataframe\" could have been accomplished without databases, they were included anyhow to demonstrate the concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFinalDf(all_sql_results):\n",
    "    # Put it all to a data frame\n",
    "    all_results = pd.DataFrame(all_sql_results)\n",
    "    all_results = all_results.rename(columns={0: \"claim_date\", 1: \"total_new_claims\", 2: \"covid_date\", 3: \"new_positive_cases\"})\n",
    "    fedResults = all_results[['claim_date', 'total_new_claims']]\n",
    "    fedResults = fedResults.set_index('claim_date')\n",
    "    covidResults = all_results[['covid_date', 'new_positive_cases']]\n",
    "    covidResults = covidResults.set_index('covid_date')\n",
    "    return (fedResults, covidResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Combine get/store/select data operations**\n",
    "\n",
    "This function grabs unemployment Fed data and COVID-19 data from their sources using their dedicated functions and stores it in the databases. It then calls a function all_sql_results() which queries and joins table records from fed_data and covid_data using the selectAllData() function. Finally it returns a tuple containing fedResults and covidResults from the aforementioned database query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStoreSelectData(engine):\n",
    "    # Get Fed data, store it into a db, and select contents.\n",
    "    fedData = getFedData(fed_api_settings)\n",
    "    storeFedData(fedData, engine)\n",
    "    \n",
    "    # Get Covid data, store it into a db, and select contents.\n",
    "    covidData = getCovidData()\n",
    "    storeCovidData(covidData, engine)\n",
    "    \n",
    "    # Get clean and relevant records from db.\n",
    "    all_sql_results = selectAllData(engine)\n",
    "\n",
    "    fedResults = getFinalDf(all_sql_results)[0]\n",
    "    covidResults = getFinalDf(all_sql_results)[1]\n",
    "    \n",
    "    return (fedResults, covidResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. Visualize the data**\n",
    "\n",
    "This function grabs the final Fed/unemployment and COVID-19 data from functions above, and sets up a 2-figure plot, each displaying two time series. The first plot displays raw total numbers of both initial unemployment claims reported by the Federal Reserve and the total number of new COVID-19 cases for each specific week. The second chart displays the percentage change for each specific week. The period of weeks covered starts from January 2020 and goes to March 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(engine):\n",
    "    fedResults = getStoreSelectData(engine)[0]\n",
    "    covidResults = getStoreSelectData(engine)[1]\n",
    "        \n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    \n",
    "    blue = mpatches.Patch(color='#5594c4', label='Initial Unemployment Claims')\n",
    "    red = mpatches.Patch(color='#ff9c46', label='New cases')\n",
    "    \n",
    "    plt.legend(handles=[red, blue], title='Legend', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Amount')\n",
    "    \n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.plot(fedResults)\n",
    "    ax1.plot(covidResults)\n",
    "    \n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    \n",
    "    fedResults['percent_change'] = fedResults['total_new_claims'].pct_change()\n",
    "    fedResults = fedResults.replace([np.inf, -np.inf], np.nan)\n",
    "    fedResults = fedResults.dropna()\n",
    "    fedResults = fedResults[['percent_change']]\n",
    "    \n",
    "    covidResults['percent_change'] = covidResults['new_positive_cases'].pct_change()\n",
    "    covidResults = covidResults.replace([np.inf, -np.inf], np.nan)\n",
    "    covidResults = covidResults.dropna()\n",
    "    covidResults = covidResults[['percent_change']]\n",
    "\n",
    "    ax2.plot(fedResults)\n",
    "    ax2.plot(covidResults)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['fed'] = fedResults['percent_change'][:-1]\n",
    "    df['covid'] = covidResults['percent_change']\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. Execute the visualization**\n",
    "\n",
    "This is just a function call that runs EVERYTHING (except whatever is below the next cell), sets labels and colors and tick intervals, and finally displays the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14. Display correlation**\n",
    "\n",
    "This function computes the correlation between percent changes in initial unemployment claims and new positive COVID-19 cases for each week. The the correlation is to zero, the weaker the  relationship. Positive values indicate a positive correlations where both variables tend to increase together. Negative values indicate a negative correlation where both variables tend to move opposite each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorrelation():\n",
    "    all_sql_results = selectAllData(engine)\n",
    "\n",
    "    fedResults = getFinalDf(all_sql_results)[0]\n",
    "    fedResults['percent_change'] = fedResults['total_new_claims'].pct_change()\n",
    "    fedResults = fedResults.replace([np.inf, -np.inf], np.nan)\n",
    "    fedResults = fedResults.dropna()\n",
    "    fedResults = fedResults[['percent_change']]\n",
    "\n",
    "    covidResults = getFinalDf(all_sql_results)[1]\n",
    "    covidResults['percent_change'] = covidResults['new_positive_cases'].pct_change()\n",
    "    covidResults = covidResults.replace([np.inf, -np.inf], np.nan)\n",
    "    covidResults = covidResults.dropna()\n",
    "    covidResults = covidResults[['percent_change']]\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['fed'] = fedResults['percent_change'][:-1]\n",
    "    df['covid'] = covidResults['percent_change']\n",
    "\n",
    "    correlation = df['fed'].corr(df['covid'])\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15. Functional testing**\n",
    "\n",
    "This cell simply loads some data and then runs simple tests of all the functions, which are mostly testing for lengths of records. The database \"store\" functions assume tables are already populated with the expected data within the hard-coded time range.\n",
    "\n",
    "An extra record exist until the selection phase, where a nan value is dropped in one of the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedData = getFedData(fed_api_settings)\n",
    "covidData = getCovidData()\n",
    "all_sql_results = selectAllData(engine)\n",
    "\n",
    "def test_getFedData():\n",
    "    assert len(getFedData(fed_api_settings)) == 61\n",
    "\n",
    "def test_storeFedData(fedData, engine):\n",
    "    results = %sql SELECT * FROM fed_data ORDER BY date ASC\n",
    "    assert len(results) == 61\n",
    "\n",
    "def test_selectFedData(engine):\n",
    "    assert len(selectFedData(engine)) == 61\n",
    "    \n",
    "def test_getCovidData():\n",
    "    assert len(getCovidData()) == 61\n",
    "\n",
    "def test_storeCovidData(covidData, engine):\n",
    "    results = %sql SELECT * FROM covid_data ORDER BY date ASC\n",
    "    assert len(results) == 60\n",
    "\n",
    "def test_selectCovidData(engine):\n",
    "    assert len(selectCovidData(engine)) == 60\n",
    "\n",
    "def test_selectAllData(engine):\n",
    "    assert len(selectAllData(engine)) == 60\n",
    "\n",
    "def test_getFinalDf(all_sql_results):\n",
    "    assert len(getFinalDf(all_sql_results)) == 2\n",
    "\n",
    "def test_getStoreSelectData(engine):\n",
    "    assert len(getStoreSelectData(engine)) == 2\n",
    "\n",
    "def test_getCorrelation():\n",
    "    assert isinstance(getCorrelation(), np.float64)\n",
    "\n",
    "test_getFedData()\n",
    "test_storeFedData(fedData, engine)\n",
    "test_selectFedData(engine)\n",
    "test_storeCovidData(covidData, engine)\n",
    "test_selectCovidData(engine)\n",
    "test_selectAllData(engine)\n",
    "test_getFinalDf(all_sql_results)\n",
    "test_getStoreSelectData(engine)\n",
    "test_getCorrelation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
