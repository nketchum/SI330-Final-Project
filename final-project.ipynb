{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI 330 Final Project\n",
    "### Nicholas Ketchum, SI 330, Winter 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project create a visualization and correlation between unemployment insurance claims recorded by the Federal Reserve and covid cases in the United States. It uses public APIs and datasets to gather information, clean it, and store in a database. It then makes calculations and plots a visualization using dataframes. \n",
    "\n",
    "### Motivation\n",
    "See how new positive COVID-19 cases and initial unemployment claims (newly unemployed individuals) were affected what the correlation is between new cases and initial unemployment claims over a one-year period. I chose this comparison because of public attention and controversy debating how these two variables (among many others) are possibly correlated. Is there a correlation? What do the charts look like when initial unemployment claims are plotting next to new positive COVID-19 cases.\n",
    "\n",
    "### Input\n",
    "\n",
    "1. Dataset One\n",
    " - Name: Initial unemployment insurance claims (seasonally-adjusted) from the Federal Reserve\n",
    " - Size: 2831 records\n",
    " - Location: https://fred.stlouisfed.org/docs/api/fred/series_observations.html\n",
    " - Format: JSON\n",
    " - Access Method: Public API with access key\n",
    "\\\n",
    "&nbsp;\n",
    "2. Dataset Two\n",
    " - Name: The Covid Tracking Project\n",
    " - Size: 25921 records\n",
    " - Location: https://covidtracking.com/data/download\n",
    " - Format: CSV\n",
    " - Access Method: HTTP\n",
    " \n",
    "### Output\n",
    "\n",
    "1. Visualization One\n",
    " - Total initial unemployment claims (red)\n",
    " - Total new positive COVID-19 cases (blue)\n",
    " - Rolling window of total new initial unemployment claims (orange)\n",
    " - Rolling window of total new positive COVID-19 cases (sky blue)\n",
    "\\\n",
    "&nbsp;\n",
    "2. Visualization Two\n",
    " - Percent change of initial unemployment claims (red)\n",
    " - Percent change of new positive COVID-19 cases (blue)\n",
    " - Rolling window of percentage change of initial unemployment claims (orange)\n",
    " - Rolling window of percentage change of new positive COVID-19 cases (sky blue)\n",
    "\\\n",
    "&nbsp;\n",
    "3. Correlation\n",
    " - Provides a numeric correlation and interpretation of changes in unemployment claims COVID-19 cases.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Install these python modules:\n",
    "    - matplotlib\n",
    "    - numpy\n",
    "    - pandas\n",
    "    - requests\n",
    "    - sql\n",
    "2. Run each code cell, in order, and check for the printing verification message before continuing.\n",
    "3. Cells 1-11 just load modules, functions, and populate variables. There's no output except the verification message.\n",
    "4. Execute Visulations and other results starts at item 12.\n",
    "5. If execution problems arise, restart the kernel and try re-running each code cell in order. It is important each preceeding cell is executed before running the current cell.\n",
    "\n",
    "### Design Notes\n",
    "\n",
    "1. The databases tables are only created and populated once to reserve resources, emulating processes which would be useful for much larger datasets where only portions of data may be remotely retrieved and added to database. This avoids re-requesting the same data. Once data is in the database we can just use that for faster and more polite execution.\n",
    "\n",
    "2. Daily COVID data retreived from the public CSV could easily be resampled into weekly records but that's not done here. Instead, each daily COVID record is stored in a dedicated table in the database. Weekly unemployment information is also stored in another table. Then, weekly numbers for both are selected by a JOIN ON a per-week data, which ssums the COVID numbers for that entire week. (See cell number 7 for details.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Establish a database connection**\n",
    "\n",
    "Using the sql extension and th sqlalchemy library, we will connect to the default database configuration provided by Jupyter through MichiganMads.org. This database will store data pulled from APIs and other sources for storage and queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a database connection.\n",
    "%load_ext sql\n",
    "%sql postgres://jovyan:si330studentuser@localhost:5432/si330\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('postgres://jovyan:si330studentuser@localhost:5432/si330')\n",
    "display('SQL loaded and database is initialized.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Import libraries and set data source variables**\n",
    "\n",
    "First, we go ahead and import all the other libraries we'll need in one spot. This makes it easier to keep track of what we've imported. For some reason, pandas requires an import of register_matplotlib_converters to properly plot some of my data.\n",
    "\n",
    "The next thing this cell does is execute register_matplotlib_converters() to load the pandas plotting extension, and then define my own specific Fed API key, for which I had to register, and the Fed API headers, which I like keeping one spot for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import requests\n",
    "\n",
    "# For some reason the \"register_matplotlib_converters\" class\n",
    "# is required for plotting on this platform.\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# Storing Fed api key and headers in one spot for more flexibility.\n",
    "FED_API_KEY = \"a964732354e30d669470642ff6b45f4c\"\n",
    "\n",
    "fed_api_settings = {\n",
    "    'series_id': 'ICSA',\n",
    "    'file_type': 'json',\n",
    "    'sort_order': 'desc',\n",
    "    'observation_start': \"2020-01-07\", # Trying to match the static end/start dates\n",
    "    'observation_end': \"2021-03-07\",   # provided by the Covid tracker.\n",
    "    'limit': '1300'\n",
    "}\n",
    "\n",
    "display('Python modules and settings() are loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Retrieve Fed data from a public API using JSON**\n",
    "\n",
    "This function takes the predefined headers and API key and makes a request to gather one year's worth of data roughly aligning with the first year of the COVID-19 outbreak. It requests the JSON data, then rerads it into a dataframe, and then refactored (cleaned) into a new data frame that has a converted string date with an extra day added to each to align these dates with dates in the COVID-19 data set, which allows for joins.\n",
    "\n",
    "The additional day is immaterial because these are weekly measurements. Because we're looking at overall trends in rough form, we're not concerned if data is off by one day; we're looking at chart shapes more generally.\n",
    "\n",
    "Finally, the dataframe's index is set using the date column, and columns are renamed for clarity and convience before returning the dataframe to the original function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weekly numbers from a public API.\n",
    "# This function is called later on, but only if the database is empty.\n",
    "def getFedData(settings):\n",
    "    headers = \"?series_id=\" + settings['series_id'] + \"&api_key=\" + FED_API_KEY + \"&file_type=\" + settings['file_type'] + \"&sort_order=\" + settings['sort_order'] + \"&observation_start=\" + settings['observation_start'] + \"&observation_end=\" + settings['observation_end'] + \"&limit=\" + str(settings['limit'])\n",
    "    url = \"https://api.stlouisfed.org/fred/series/observations\" + headers\n",
    "    df = pd.read_json(url)\n",
    "    ndf = pd.DataFrame()\n",
    "    week_no = 61\n",
    "    for group, row in df.iterrows():\n",
    "        # Covid data is one day behind Fed data.\n",
    "        # To make our lives easier, let's add one day to Fed data so we can match records.\n",
    "        # A one-day delta is immaterial for our overall measurement and analysis.\n",
    "        ndf.loc[group, 'date'] = pd.to_datetime(df.iloc[group]['observations']['date']) + pd.Timedelta(days=1)\n",
    "        ndf.loc[group, 'week_no'] = week_no\n",
    "        week_no = week_no - 1\n",
    "        ndf.loc[group, 'total_new_claims'] = int(df.iloc[group]['observations']['value'])\n",
    "    ndf.set_index('date', inplace=True)\n",
    "    return ndf\n",
    "\n",
    "display('getFedData() is loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Store Fed data into the database**\n",
    "\n",
    "This function creates a table to store Fed data. It drops any pre-existing tables, creates a new table with two columns: date (timestamp) and claims (integer). Then, the data is loaded from a dataframe by using the .to_sql() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store fed data in a db tabe.\n",
    "def storeFedData(df, engine):\n",
    "    %sql CREATE TABLE IF NOT EXISTS fed_data(date timestamp, claims integer, week_no integer, PRIMARY KEY(date))\n",
    "    df.to_sql('fed_data', engine)\n",
    "\n",
    "display('storeFedData() is loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Retrieve COVID-19 data from a public CSV file**\n",
    "\n",
    "This function requests a public CSV file listed at covidtracking.com. It uses the pandas read_csv method to convert the CSV data into a dataframe. Then, a new dataframe is created which stores a reformatted date and converts it into a pandas datetime.\n",
    "\n",
    "Nans are replaced with zeros to keep the dataframe shape the same as the Fed dataframe (keeping an identical row count), its positive_cases column datatype is converted to an integer using the apply() function to cast data as an int(), and then set as the dataframe index.\n",
    "\n",
    "Finally, the dataframe is resampled to a weekly interval, summing up the new cases from each day that week. Then the final, cleaned dataframe is returned to the original calling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cases from a public csv.\n",
    "# Clean the data a bit by reformatting the date to match the other\n",
    "# data source, and count the week numbers so we can do a GROUP BY\n",
    "# week number later on in this program when we do a database query.\n",
    "# Eventually we only want weekly numbers.\n",
    "def getCovidData():\n",
    "    url = 'https://api.covidtracking.com/v1/us/daily.csv'\n",
    "    # Entire dataframe with everything.\n",
    "    df = pd.read_csv(url)\n",
    "    # Empty dataframe will store what we need.\n",
    "    ndf = pd.DataFrame()\n",
    "    day_no = 0\n",
    "    week_no = 61\n",
    "    ndf['week_no'] = ''\n",
    "    for group, row in df.iterrows():\n",
    "        # Format the data similar to Fed data.\n",
    "        date = row['date']\n",
    "        date = str(date)\n",
    "        year = date[0:4]\n",
    "        day = date[4:6]\n",
    "        month = date[6:8]\n",
    "        ndf.loc[group, 'week_no'] = week_no\n",
    "        # Track the weeks.\n",
    "        if day_no % 7 == 0:\n",
    "            week_no = week_no - 1\n",
    "        day_no = day_no + 1\n",
    "        date = year + '-' + day + '-' + month\n",
    "        # Make date into a datetime type.\n",
    "        ndf.loc[group, 'date'] = pd.to_datetime(date)\n",
    "        positive_cases = row['positiveIncrease']\n",
    "        ndf.loc[group, 'positive_cases'] = positive_cases\n",
    "    # Get rid of empty yrecords.\n",
    "    ndf = ndf.replace(np.nan, 0)\n",
    "    # Convert positive case column type into an int.\n",
    "    ndf['positive_cases'] = ndf['positive_cases'].apply(int)\n",
    "    # Index via datetime.\n",
    "    ndf.set_index('date', inplace=True)\n",
    "    # Resample as a weekly sum of new cases.\n",
    "    # We could resample if we weren't relying on databases joins\n",
    "    # to match unemployment claim datess to new covid numbers.\n",
    "    # ndf = ndf.resample('W').sum() \n",
    "    return ndf\n",
    "\n",
    "display('getCovidData() is loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Store COVID-19 data into the database**\n",
    "\n",
    "This function creates a table to store COVID-19 data. It drops any pre-existing tables, creates a new table with two columns: date (timestamp) and positive_cases (integer). Then, the data is loaded from a dataframe by using the .to_sql() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store fed data in a db tabe.\n",
    "def storeCovidData(df, engine):\n",
    "    %sql CREATE TABLE IF NOT EXISTS covid_data(date timestamp, positive_cases integer, week_no integer, PRIMARY KEY(date))\n",
    "    df.to_sql('covid_data', engine)\n",
    "\n",
    "display('storeCovidData() is loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Select everthing stored in the database**\n",
    "\n",
    "This function joins the fed_data and covid_data table on the data field. This results in each record containing a date, number of new unemployment claims in a particular week, the number of new COVID-19 cases identified in that same week, and returns the data as a sql result set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select final records in a single master query.\n",
    "# This accomplishes something very similar to a DataFrame \"merge\" in that it pairs two sets of\n",
    "# records together in a RIGHT JOIN which limits data to unemployment claims, which is the smaller\n",
    "# of the two data sets, and have the time intervals we are interested in measuring.\n",
    "# We're grouping on week_no so we can SUM up the values for COVID cases during that week.\n",
    "def selectAllData(engine):\n",
    "    # Covid data is daily but Fed data is weekly. The join and grouping takes care of that.\n",
    "    results = %sql SELECT f.date, f.total_new_claims, f.week_no, c.date, c.positive_cases FROM (SELECT date, week_no, SUM(positive_cases) AS positive_cases FROM covid_data GROUP BY date, week_no, positive_cases) c RIGHT JOIN fed_data f ON f.week_no = c.week_no AND f.date = c.date ORDER BY f.date ASC;\n",
    "    return results\n",
    "\n",
    "display('selectAllData() is loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a much more readable version of the above SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%sql\n",
    "# SELECT f.date, f.total_new_claims, f.week_no, c.date, c.positive_cases\n",
    "# FROM (\n",
    "#     SELECT date, week_no, SUM(positive_cases) AS positive_cases\n",
    "#     FROM covid_data\n",
    "#     GROUP BY date, week_no, positive_cases\n",
    "#     ) c \n",
    "# RIGHT JOIN fed_data f \n",
    "# ON f.week_no = c.week_no AND f.date = c.date\n",
    "# ORDER BY f.date ASC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Create a two dataframes for each datasest from the returned database queries**\n",
    "\n",
    "This function takes the sql result set returned from the above function, converts it into a \"master\" dataframe, renames the columns from integer indexes to readable lables, and sets the index using the date. Then, two new dataframes are created using the master dataframe: one for unemployment (Fed) and one for COVID-19. Both dataframes are returned to the original calling function as a tuple.\n",
    "\n",
    "\n",
    "Although created a \"master dataframe\" could have been accomplished without databases, they were included anyhow to demonstrate the concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes the master SQL query result, puts it into a DataFrame\n",
    "# which is reindexed and columns renamed.\n",
    "def getFinalDf(all_sql_results):\n",
    "    # Put it all to a data frame\n",
    "    all_results = pd.DataFrame(all_sql_results)\n",
    "    all_results = all_results.rename(columns={0: \"claim_date\", 1: \"total_new_claims\", 2: \"week_no\", 3: \"covid_date\", 4: \"new_positive_cases\"})\n",
    "    fedResults = all_results[['claim_date', 'total_new_claims']]\n",
    "    fedResults = fedResults.set_index('claim_date')\n",
    "    covidResults = all_results[['covid_date', 'new_positive_cases']]\n",
    "    covidResults = covidResults.set_index('covid_date')\n",
    "    return (fedResults, covidResults)\n",
    "\n",
    "display('all_sql_results() is loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Combine get/store/select data operations**\n",
    "\n",
    "This function grabs unemployment Fed data and COVID-19 data from their sources using their dedicated functions and stores it in the databases. It then calls a function all_sql_results() which queries and joins table records from fed_data and covid_data using the selectAllData() function. Finally it returns a tuple containing fedResults and covidResults from the aforementioned database query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only grab and store data if database tables are empty.\n",
    "# Otherwise this function calls getFinalDf for each sql data set\n",
    "# from the databases, receives two dataframes which is returned\n",
    "# from this function as a tuple.\n",
    "def getStoreSelectData(engine):\n",
    "    # Get Fed data, store it into a db, and select contents.\n",
    "    fed_data = %sql SELECT * FROM fed_data;\n",
    "    if not len(fed_data):\n",
    "        storeFedData(getFedData(fed_api_settings), engine)\n",
    "    \n",
    "    # Get Covid data, store it into a db, and select contents.\n",
    "    covid_data = %sql SELECT * FROM covid_data;\n",
    "    if not len(covid_data):\n",
    "        storeCovidData(getCovidData(), engine)\n",
    "    \n",
    "    # Get clean and relevant records from db.\n",
    "    all_sql_results = selectAllData(engine)\n",
    "\n",
    "    # Extract each set of results from tuple.\n",
    "    fedResults = getFinalDf(all_sql_results)[0]\n",
    "    covidResults = getFinalDf(all_sql_results)[1]\n",
    "    \n",
    "    return (fedResults, covidResults)\n",
    "\n",
    "display('getStoreSelectData() is loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Convert a decimal into a float**\n",
    "\n",
    "This is used for an apply function later in the program. A simpler method exists to do this, but I'd like to demonstrate an apply function that uses its own logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFloat(row):\n",
    "    return float(row)\n",
    "\n",
    "display('makeFloat() is loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Visualize the data**\n",
    "\n",
    "This function grabs the final Fed/unemployment and COVID-19 data from functions above, and sets up a 2-figure plot, each displaying two time series. The first plot displays raw total numbers of both initial unemployment claims reported by the Federal Reserve and the total number of new COVID-19 cases for each specific week. The second chart displays the percentage change for each specific week. The period of weeks covered starts from January 2020 and goes to March 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(engine):\n",
    "    \n",
    "    from matplotlib.ticker import StrMethodFormatter\n",
    "    import matplotlib.ticker as plticker\n",
    "    \n",
    "    # Set up the dataframes from database data.\n",
    "    fedResults = pd.DataFrame(getStoreSelectData(engine)[0])\n",
    "    covidResults = pd.DataFrame(getStoreSelectData(engine)[1])[1:]\n",
    "\n",
    "    # Get the overall figure sets up.\n",
    "    fig = plt.figure(figsize = (40, 10), facecolor =\"lightgrey\" )\n",
    "    fig.suptitle('Unemployment Claims vs. COVID-19 Cases', fontsize=12)\n",
    "    \n",
    "    # Set plot one colors and labels.\n",
    "    red = mpatches.Patch(color='r', label='New total claims')\n",
    "    orange = mpatches.Patch(color='orange', label='Rolling average')\n",
    "    blue = mpatches.Patch(color='b', label='New positive cases')\n",
    "    sky = mpatches.Patch(color='#87ceeb', label='Rolling average')\n",
    "\n",
    "    # Add total claims and cases totals subplot.\n",
    "    subplot = fig.add_subplot(121)\n",
    "    subplot.legend(handles=[red, orange, blue, sky], title='Claims & Cases', bbox_to_anchor=(1, 1), loc='upper left')\n",
    "    subplot.plot(fedResults.index, fedResults['total_new_claims'], 'r')\n",
    "    subplot.plot(fedResults.index, fedResults['total_new_claims'].rolling(14).mean(), 'orange')\n",
    "    subplot.plot(covidResults.index, covidResults['new_positive_cases'], 'b')\n",
    "    subplot.plot(covidResults.index, covidResults['new_positive_cases'].rolling(14).mean(), '#87ceeb')\n",
    "    \n",
    "    # Add labels.\n",
    "    subplot.set_title(label = \"Total Claims and Cases\", fontsize=10)\n",
    "    subplot.set_xlabel(xlabel = \"Date\", fontsize=10)\n",
    "    subplot.set_ylabel(ylabel = \"Number of Claims\", fontsize=10)\n",
    "    \n",
    "    # Manipulate tick size and establish a grid.\n",
    "    plt.xticks(fontsize=6)\n",
    "    plt.yticks(fontsize=8)\n",
    "    loc = plticker.MultipleLocator(base=12.5) # this locator puts ticks at regular intervals\n",
    "    plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    plt.grid()\n",
    "\n",
    "    # Calculate Fed total_new_claims percent change.\n",
    "    fedResults['percent_change'] = fedResults['total_new_claims'].pct_change()\n",
    "    fedResults = fedResults.replace([np.inf, -np.inf], np.nan)\n",
    "    fedResults = fedResults.dropna()\n",
    "    fedResults = fedResults[['percent_change']]\n",
    "    fedResults['percent_change'] = fedResults['percent_change'].apply(lambda x: x * 100)\n",
    "    \n",
    "    # Calculate COVID-19 new_positive_cases percent change.\n",
    "    covidResults['new_positive_cases'] = covidResults['new_positive_cases'].apply(makeFloat)\n",
    "    covidResults['percent_change'] = covidResults['new_positive_cases'].pct_change()\n",
    "    covidResults = covidResults.replace([np.inf, -np.inf], np.nan)\n",
    "    covidResults = covidResults.dropna()\n",
    "    covidResults = covidResults[['percent_change']]\n",
    "    covidResults['percent_change'] = covidResults['percent_change'].apply(lambda x: x * 100)\n",
    "    \n",
    "    # Add claims and cases percentage change subplot.\n",
    "    subplot = fig.add_subplot(122)\n",
    "    subplot.plot(fedResults.index, fedResults['percent_change'], 'r')\n",
    "    subplot.plot(fedResults.index, fedResults['percent_change'].rolling(14).mean(), 'orange')\n",
    "    subplot.plot(covidResults.index, covidResults['percent_change'], 'b')\n",
    "    subplot.plot(covidResults.index, covidResults['percent_change'].rolling(14).mean(), '#87ceeb')\n",
    "    \n",
    "    # Set plot two colors and labels.\n",
    "    red = mpatches.Patch(color='r', label='Percent change in claims')\n",
    "    orange = mpatches.Patch(color='orange', label='Rolling average')\n",
    "    blue = mpatches.Patch(color='b', label='Percent change in positive cases')\n",
    "    sky = mpatches.Patch(color='#87ceeb', label='Rolling average')\n",
    "    \n",
    "    # Add total claims and cases percent change subplot.\n",
    "    subplot.legend(handles=[red, orange, blue, sky], title='Percent Change', bbox_to_anchor=(1, 1), loc='upper left')\n",
    "    subplot.set_title(label = \"Percent Change in Claims and Cases\", fontsize=10)\n",
    "    subplot.set_xlabel(xlabel = \"Date\", fontsize=10)\n",
    "    subplot.set_ylabel(ylabel = \"Percent Change\", fontsize=10)\n",
    "    \n",
    "    # Manipulate tick size and establish a grid.\n",
    "    plt.xticks(fontsize=6)\n",
    "    plt.yticks(fontsize=8)\n",
    "    loc = plticker.MultipleLocator(base=12.5) # this locator puts ticks at regular intervals\n",
    "    plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    plt.grid()\n",
    "    \n",
    "    # Draw plots.\n",
    "    plt.draw()\n",
    "\n",
    "display('visualize() is loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View The Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. Execute the visualization**\n",
    "\n",
    "This is just a function call that runs EVERYTHING (except whatever is below the next cell), sets labels and colors and tick intervals, and finally displays the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12.1. What can we say about the above plots?**\n",
    "\n",
    "Comparing the two charts, we see a couple things. We see when COVID-19 really entered the picture in March 2020, initial unemployment claims spiked, then dropped off (perhaps because only one initial claim can be filed), and then claims stablized a bit as the virus spread. But then, in 2022, total positive cases increased more than last year, while initial unemployment claims did not spike, but more closely matched the pattern of the COVID-19 data.\n",
    "\n",
    "Also, because initial unemployment claims are a one-time mechanism, the drop off does not indicate continued unemployment claims have remained higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. Calculate correlation**\n",
    "\n",
    "This function computes the correlation between percent changes in initial unemployment claims and new positive COVID-19 cases for each week. The the correlation is to zero, the weaker the  relationship. Positive values indicate a positive correlations where both variables tend to increase together. Negative values indicate a negative correlation where both variables tend to move opposite each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorrelation():\n",
    "    all_sql_results = selectAllData(engine)\n",
    "\n",
    "    fedResults = pd.DataFrame(getStoreSelectData(engine)[0])\n",
    "    fedResults['percent_change'] = fedResults['total_new_claims'].pct_change()\n",
    "    fedResults = fedResults.replace([np.inf, -np.inf], np.nan)\n",
    "    fedResults = fedResults.dropna()\n",
    "    fedResults = fedResults[['percent_change']]\n",
    "\n",
    "    covidResults = pd.DataFrame(getStoreSelectData(engine)[1])[1:]\n",
    "    covidResults['new_positive_cases'] = covidResults['new_positive_cases'].apply(makeFloat)\n",
    "    covidResults['percent_change'] = covidResults['new_positive_cases'].pct_change()\n",
    "    covidResults = covidResults.replace([np.inf, -np.inf], np.nan)\n",
    "    covidResults = covidResults.dropna()\n",
    "    covidResults = covidResults[['percent_change']]\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['fed'] = fedResults['percent_change'][:-1]\n",
    "    df['covid'] = covidResults['percent_change']\n",
    "\n",
    "    correlation = df['fed'].corr(df['covid'])\n",
    "    \n",
    "    # https://towardsdatascience.com/eveything-you-need-to-know-about-interpreting-correlations-2c485841c0b8\n",
    "    if correlation > 0.9:\n",
    "        print('There is a very high positive correleation of', correlation)\n",
    "    elif correlation > 0.7:\n",
    "        print('There is a high positive correleation of', correlation)\n",
    "    elif correlation > 0.5:\n",
    "        print('There is a moderate positive correleation of', correlation)\n",
    "    elif correlation > 0.3:\n",
    "        print('There is a low positive correleation of', correlation)\n",
    "    elif (correlation < 0.3) and (correlation > -0.3):\n",
    "        print('There is a neglible correlation of', correlation)\n",
    "    elif correlation > -0.3:\n",
    "        print('There is a low negative correleation of', correlation)\n",
    "    elif correlation > -0.5:\n",
    "        print('There is a moderate negative correleation of', correlation)\n",
    "    elif correlation > -0.7:\n",
    "        print('There is a high negative correleation of', correlation)\n",
    "    else:\n",
    "        print('There is a very high positive correleation of', correlation)\n",
    "\n",
    "display('getCorrelation() is loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14. Display corrrelation**\n",
    "\n",
    "This simply calls the above function and displays the correlation as a decimal/float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCorrelation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14.1. What can we say about the correlation?**\n",
    "\n",
    "Initial unemployment claims and new positive COVID-19 cases have a low correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15. Functional testing**\n",
    "\n",
    "This cell simply loads some data and then runs simple tests of all the functions, which are mostly testing for lengths of records. The database \"store\" functions assume tables are already populated with the expected data within the hard-coded time range.\n",
    "\n",
    "An extra record exist until the selection phase, where a nan value is dropped in one of the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedData = getFedData(fed_api_settings)\n",
    "covidData = getCovidData()\n",
    "all_sql_results = selectAllData(engine)\n",
    "\n",
    "def test_getFedData():\n",
    "    assert len(getFedData(fed_api_settings)) == 61\n",
    "\n",
    "def test_storeFedData(fedData, engine):\n",
    "    results = %sql SELECT * FROM fed_data ORDER BY date ASC\n",
    "    assert len(results) == 61\n",
    "    \n",
    "def test_getCovidData():\n",
    "    assert len(getCovidData()) == 61\n",
    "\n",
    "def test_storeCovidData(covidData, engine):\n",
    "    results = %sql SELECT * FROM covid_data ORDER BY date ASC\n",
    "    assert len(results) == 420\n",
    "\n",
    "def test_selectAllData(engine):\n",
    "    assert len(selectAllData(engine)) == 61\n",
    "\n",
    "def test_getFinalDf(all_sql_results):\n",
    "    assert len(getFinalDf(all_sql_results)) == 2\n",
    "\n",
    "def test_getStoreSelectData(engine):\n",
    "    fed_data = %sql SELECT * FROM fed_data;\n",
    "    if len(fed_data) > 0:\n",
    "        assert len(getStoreSelectData(engine)) == 2\n",
    "\n",
    "test_getFedData()\n",
    "test_storeFedData(fedData, engine)\n",
    "test_storeCovidData(covidData, engine)\n",
    "test_selectAllData(engine)\n",
    "test_getFinalDf(all_sql_results)\n",
    "test_getStoreSelectData(engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
